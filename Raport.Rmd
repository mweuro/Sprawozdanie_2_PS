---
title: "Sprawozdanie 2"
author: "Szymon Malec, Michał Wiktorowski"
output:
  pdf_document: 
    number_sections: true
    extra_dependencies: ["polski", "mathtools", "amsthm", "amssymb", "icomma", "upgreek", "xfrac", "scrextend", "float", "tabularx", "hyperref", "caption", "enumitem", "titlesec"]
fontsize: 12pt
---

\renewcommand{\figurename}{Wykres}
\renewcommand{\tablename}{Tablica}
\raggedbottom
\titlelabel{\thetitle.\quad}

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE, eval = TRUE, fig.pos = "H")
```

```{r}
library(ggplot2)
library(dplyr)
library(tidyr)
library(knitr)
```




\section{Wstęp}

|       Niniejsza praca poświęcona jest przedstawieniu trzech testów dla parametru proporcji (prawdopodobieństwa sukcesu w próbie Bernoulliego) rozkładu dwumianowego. Dla pewnej realizacji zmiennej losowej $S \sim \mathcal{B}(n, p)$ rozważmy hipotezy:
\begin{itemize}
\item $H_0$: $p = p_0 = 0.5$
\item $H_1$: $p \neq p_0 = 0.5$,
\end{itemize}
gdzie $H_0$ i $H_1$ są odpowiednio hipotezą zerową i alternatywną. Sprawdzimy ich poprawność przy użyciu trzech testów:
\begin{itemize}
\item testu opartego o $\textbf{przedział Wilsona}$,
\item testu opartego o $\textbf{przedział Cloppera-Pearsona}$,
\item testu opartego o $\textbf{przedział Jeffreysa}$,
\end{itemize}
na poziomie istotności $\alpha = 0.05$. Następnie poddamy każdy z testów analizie - zobaczymy, jak zachowuje się ich moc i na tej podstawie stwierdzimy, który test jest najmocniejszy.





\section{Test oparty o przedział Wilsona}

|       Do konstrukcji przedziału wykorzystamy fakt, że rozkład dwumianowy można przybliżać rozkładem normalnym. Przyjmuje się, że przybliżenie to jest dobre, gdy $np > 5$, $n(1 - p) > 5$ oraz wartość $p$ jest bliskia 0.5. Wartość oczekiwana $S$ to $\mathrm{E}S = np$, a odchylenie standardowe równe jest $\mathrm{Std}(S) = \sqrt{np(1-p)}$, zatem dla pewnej zmiennej losowej $Z \sim \mathcal{N}(0, 1)$ możemy powiedzieć, że
$$
\frac{S - np_0}{\sqrt{np_0(1 - p_0)}} \stackrel{\mathrm{d}}{\approx} Z
$$
pod warunkiem, że $H_0$ jest prawdziwa. Korzystając z tego, zapisujemy
$$
\mathrm{P}\left( -z < \frac{S - np_0}{\sqrt{np_0(1 - p_0)}} < z \right) \approx 1 - \alpha,
$$
gdzie $z$ jest kwantylem rzędu $1 - \frac{\alpha}{2}$ rozkładu $\mathcal{N}(0, 1)$. Podnosząc strony nierówności wewnątrz funkcji prawdopodobieństwa do kwadratu dostajemy
$$
\mathrm{P}\left( \frac{(S - np_0)^2}{np_0(1 - p_0)} < z^2 \right) \approx 1 - \alpha,
$$
a następnie roziązując ukytą wewnątrz nierówność kwadratową względem $p_0$ otrzymamy
$$
\mathrm{P}(p_0 \in W) \approx 1 - \alpha,
$$
gdzie
$$
W = \left[ \frac{S + \frac{1}{2}z^2}{n + z^2} - \frac{z}{n + z^2} \sqrt{\frac{S(n - S)}{n} + \frac{z^2}{4}} \ , \ \ \frac{S + \frac{1}{2}z^2}{n + z^2} + \frac{z}{n + z^2} \sqrt{\frac{S(n - S)}{n} + \frac{z^2}{4}} \right].
$$
nazywamy przedziałem Wilsona. Widzimy zatem, że przedział ten będzie zmieniać się w zależności od wartości $S$ i jeśli hipoteza zerowa jest prawdziwa, $p_0$ będzie wpadać do niego z częstością zbliżoną do $1 - \alpha$.






\section{Test oparty o przedział Cloppera-Pearsona}

|       Oznaczmy kwantyl rzędu $\gamma$ rozkładu $\mathcal{B}eta(\alpha, \beta)$ jako $b_{\gamma}(\alpha, \beta)$. Dla pewnej realizacji zmiennej $S$, przedział Cloppera-Pearsona przedstawia się w postaci
$$
CP = \left[ b_{\frac{\alpha}{2}}(S, \ n - S + 1), \ \ b_{1 - \frac{\alpha}{2}}(S + 1, \ n - S) \right],
$$
gdzie
$$
\mathrm{P}(p_0 \in CP) \approx 1 - \alpha
$$
pod warunkiem prawdziwości hipotezy zerowej.



\section{Test oparty o przedział Jeffreysa}
|       Przedział ten definiuje się podobnie jak przedział Cloppera-Pearsona, z tą różnicą że tutaj korzystamy wyłącznie z kwantyli rozkładu $\mathcal{B}(S + 0.5, \ n - S + 0.5)$. Dla pewnej realizacji zmiennej $S$ ma on zatem następującą postać:
$$
J = \left[ b_{\frac{\alpha}{2}}(S + 0.5, \ n - S + 0.5), \ \ b_{1 - \frac{\alpha}{2}}(S + 0.5, \ n - S + 0.5) \right],
$$
gdzie
$$
\mathrm{P}(p_0 \in J) \approx 1 - \alpha
$$
pod warunkiem, że hipoteza $H_0$ jest prawdziwa.



\section{Porównanie testów}
|     W powyższych sekcjach przedstawiliśmy trzy różne sposoby na testowanie parametru proporcji $p$ w rozkładzie dwumianowym. Istnieje jednak pytanie - który z tych testów daje nam największą pewność poprawności hipotezy? Odpowiemy na to pytanie analizując wykresy mocy dla każdego z tych testów. Rozważymy trzy różne długości prób Bernoulliego - $n \in \{7, 35, 250\}$. Dla różnych wartości $0 < p < 1$, będziemy testować hipotezę $H_0 : ~ p = 0,5$. Umożliwi nam to przedstawienie wykresu zależności mocy testu od wartości $p$.
```{r}
library(dplyr)
library(ggplot2)
library(zeallot)
library(tidyr)
library(reshape2)
library(cowplot)
library(DescTools)
options(repr.plot.width = 12, repr.plot.height = 8)
```

```{r}





plots <- function(n, p0 = 0.5,
                  alpha = 0.05,
                  N = 10000,
                  ps = seq(0.01, 0.99, 0.01)){

# Wilson
power1 <- c()
for (p in ps) {
    S <- rbinom(N, prob=p, size=n)
    z <- qnorm(1 - alpha/2)
    tests <- (S + 1/2 * z^2) / (n + z^2)  -  z / (n + z^2) * sqrt(S * (n - S) / n + z^2 / 4) < p0 & p0 < (S + 1/2 * z^2) / (n + z^2)  +  z / (n + z^2) * sqrt(S * (n - S) / n + z^2 / 4)
    power1 <- append(power1, 1 - sum(tests) / N)
}

# Clopper-Pearson
power2 <- c()
for (p in ps) {
    S <- rbinom(N, size=n, prob=p)
    tests <- pbinom(S, size=n, prob=p0) > alpha/2  &  dbinom(S, size=n, prob=p0) + pbinom(S, size=n, prob=p0, lower.tail=FALSE) > alpha/2
    power2 <- append(power2, 1 - sum(tests) / N)
}

# Jeffreys
power3 <- c()
for (p in ps) {
    S <- rbinom(N, prob=p, size=n)
    tests <- qbeta(alpha/2, S + 0.5, n - S + 0.5) < p0  &  p0 < qbeta(1 - alpha/2, S + 0.5, n - S + 0.5)
    power3 <- append(power3, 1 - sum(tests) / N)
}

ggplot() + 
  geom_line(aes(ps, power1, col="Wilson")) + 
  geom_line(aes(ps, power2, col="Clopper-Pearson")) +
  geom_line(aes(ps, power3, col="Jeffreys")) +
  labs(x = 'p', y = 'Simulated Power')
}
```

```{r n7, fig.cap="\\label{fig:n7} Wykres zależności mocy testów od parametru $p$ dla $n = 7$", fig.width = 5, fig.height = 3, fig.align="center"}
n <- 7
plots(n)
```

```{r n35, fig.cap="\\label{fig:n35} Wykres zależności mocy testów od parametru $p$ dla $n = 35$", fig.width = 5, fig.height = 3, fig.align="center"}
n <- 35
plots(n)
```

```{r n250, fig.cap="\\label{fig:n250} Wykres zależności mocy testów od parametru $p$ dla $n = 250$", fig.width = 5, fig.height = 3, fig.align="center"}
n <- 250
plots(n)
```
\section{Podsumowanie}
