---
title: "Sprawozdanie 2"
author: "Szymon Malec, Michał Wiktorowski"
output:
  pdf_document: 
    number_sections: true
    extra_dependencies: ["polski", "mathtools", "amsthm", "amssymb", "icomma", "upgreek", "xfrac", "scrextend", "float", "tabularx", "hyperref", "caption", "enumitem", "titlesec"]
fontsize: 12pt
---

\renewcommand{\figurename}{Wykres}
\renewcommand{\tablename}{Tablica}
\raggedbottom
\titlelabel{\thetitle.\quad}

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE, eval = TRUE, fig.pos = "H")
```

```{r}
library(dplyr)
library(ggplot2)
library(tidyr)
library(knitr)
library(DescTools)


plots <- function(n, p0 = 0.5,
                  alpha = 0.05,
                  z = qnorm(1 - alpha/2),
                  N = 100,
                  ps = seq(0.01, 0.99, 0.01)){

    power1 <- c()
    power2 <- c()
    power3 <- c()

    for (p in ps) {
        S <- rbinom(N, prob=p, size=n)

        tests <- (S + 1/2 * z^2) / (n + z^2)  -  z / (n + z^2) * sqrt(S * (n - S) / n + z^2 / 4) < p0 & p0 < (S + 1/2 * z^2) / (n + z^2)  +  z / (n + z^2) * sqrt(S * (n - S) / n + z^2 / 4)
        power1 <- append(power1, 1 - sum(tests) / N)

        tests <- qbeta(alpha/2, S, n - S + 1) < p0  &  p0 < qbeta(1 - alpha/2, S + 1, n - S)
        power2 <- append(power2, 1 - sum(tests) / N)

        tests <- qbeta(alpha/2, S + 0.5, n - S + 0.5) < p0  &  p0 < qbeta(1 - alpha/2, S + 0.5, n - S + 0.5)
        power3 <- append(power3, 1 - sum(tests) / N)
    }

    ggplot() + 
      geom_line(aes(ps, power1, col="Wilson"), linewidth=0.5, alpha = 0.4) + 
      geom_line(aes(ps, power2, col="Clopper-Pearson"), linetype="dashed", linewidth=0.7) +
      geom_line(aes(ps, power3, col="Jeffreys"), linetype="dotted", linewidth=0.8) +
      labs(x = 'p', y = 'Moc testu') + 
      scale_color_manual('', 
          breaks = c('Wilson',
                    'Clopper-Pearson',
                    'Jeffreys'
                    ),
          values = c('purple', 'lightblue', 'brown'))
}


intervals <- function(n, S = 0:n, alpha = 0.05){
    intervals1 <- BinomCI(S, n, method="wilson")
    intervals2 <- BinomCI(S, n, method="clopper-pearson")
    intervals3 <- BinomCI(S, n, method="jeffreys")

    ggplot() +
      geom_point(aes(S, intervals1[,2], col="Wilson"), size = 0.3) + geom_point(aes(S, intervals1[,3], col="Wilson"), size = 0.3) +
      geom_point(aes(S, intervals2[,2], col="Clopper-Pearson"), size = 0.3) + geom_point(aes(S, intervals2[,3], col="Clopper-Pearson"), size = 0.3) +
      geom_point(aes(S, intervals3[,2], col="Jeffreys"), size = 0.3) + geom_point(aes(S, intervals3[,3], col="Jeffreys"), size = 0.3) +
      geom_line(aes(S, 0.5)) +
      labs(x = 'n', y = 'Confidence intervals') + 
      scale_color_manual('', 
          breaks = c('Wilson',
                    'Clopper-Pearson',
                    'Jeffreys'
                    ),
          values = c('purple', 'lightblue', 'brown'))
}
```




\section{Wstęp}

|       Niniejsza praca poświęcona jest przedstawieniu trzech testów dla parametru proporcji (prawdopodobieństwa sukcesu w próbie Bernoulliego) rozkładu dwumianowego. Dla pewnej realizacji zmiennej losowej $S \sim \mathcal{B}(n, p)$ rozważmy hipotezy:
\begin{itemize}
\item $H_0$: $p = p_0 = 0.5$
\item $H_1$: $p \neq p_0 = 0.5$,
\end{itemize}
gdzie $H_0$ i $H_1$ są odpowiednio hipotezą zerową i alternatywną. Sprawdzimy ich poprawność przy użyciu trzech testów:
\begin{itemize}
\item testu opartego o $\textbf{przedział Wilsona}$,
\item testu opartego o $\textbf{przedział Cloppera-Pearsona}$,
\item testu opartego o $\textbf{przedział Jeffreysa}$,
\end{itemize}
na poziomie istotności $\alpha = 0.05$. Następnie porównamy wspomniane testy pod kątem mocy, aby odpowiedzić na pytanie, czy można wyłonić wśród nich test jednostajnie najmocniejszy.





\section{Test oparty o przedział Wilsona}

|       Do konstrukcji przedziału wykorzystamy fakt, że rozkład dwumianowy można przybliżać rozkładem normalnym. Przyjmuje się, że przybliżenie to jest dobre, gdy $np > 5$, $n(1 - p) > 5$ oraz wartość $p$ jest bliskia 0.5. Wartość oczekiwana $S$ to $\mathrm{E}S = np$, a odchylenie standardowe równe jest $\mathrm{Std}(S) = \sqrt{np(1-p)}$, zatem dla pewnej zmiennej losowej $Z \sim \mathcal{N}(0, 1)$ możemy powiedzieć, że
$$
\frac{S - np_0}{\sqrt{np_0(1 - p_0)}} \stackrel{\mathrm{d}}{\approx} Z
$$
pod warunkiem, że $H_0$ jest prawdziwa. Korzystając z tego, zapisujemy
$$
\mathrm{P}\left( -z < \frac{S - np_0}{\sqrt{np_0(1 - p_0)}} < z \right) \approx 1 - \alpha,
$$
gdzie $z$ jest kwantylem rzędu $1 - \frac{\alpha}{2}$ rozkładu $\mathcal{N}(0, 1)$. Podnosząc strony nierówności wewnątrz funkcji prawdopodobieństwa do kwadratu dostajemy
$$
\mathrm{P}\left( \frac{(S - np_0)^2}{np_0(1 - p_0)} < z^2 \right) \approx 1 - \alpha,
$$
a następnie rozwiązując ukrytą wewnątrz nierówność kwadratową względem $p_0$ otrzymamy
$$
\mathrm{P}(p_0 \in W) \approx 1 - \alpha,
$$
gdzie
$$
W = \left[ \frac{S + \frac{1}{2}z^2}{n + z^2} - \frac{z}{n + z^2} \sqrt{\frac{S(n - S)}{n} + \frac{z^2}{4}} \ , \ \ \frac{S + \frac{1}{2}z^2}{n + z^2} + \frac{z}{n + z^2} \sqrt{\frac{S(n - S)}{n} + \frac{z^2}{4}} \right]
$$
nazywamy przedziałem Wilsona. Widzimy zatem, że przedział ten będzie zmieniać się w zależności od wartości $S$ i jeśli hipoteza zerowa jest prawdziwa, $p_0$ będzie wpadać do niego z częstością zbliżoną do $1 - \alpha$.






\section{Test oparty o przedział Cloppera-Pearsona}

|       Oznaczmy kwantyl rzędu $\gamma$ rozkładu $\mathcal{B}eta(\alpha, \beta)$ jako $b_{\gamma}(\alpha, \beta)$. Dla pewnej realizacji zmiennej $S$, przedział Cloppera-Pearsona przedstawia się w postaci
$$
CP = \left[ b_{\frac{\alpha}{2}}(S, \ n - S + 1), \ \ b_{1 - \frac{\alpha}{2}}(S + 1, \ n - S) \right],
$$
gdzie
$$
\mathrm{P}(p_0 \in CP) \approx 1 - \alpha
$$
pod warunkiem prawdziwości hipotezy zerowej.





\section{Test oparty o przedział Jeffreysa}

|       Przedział ten definiuje się podobnie jak przedział Cloppera-Pearsona, z tą różnicą że tutaj korzystamy wyłącznie z kwantyli rozkładu $\mathcal{B}(S + 0.5, \ n - S + 0.5)$. Dla pewnej realizacji zmiennej $S$ ma on zatem następującą postać:
$$
J = \left[ b_{\frac{\alpha}{2}}(S + 0.5, \ n - S + 0.5), \ \ b_{1 - \frac{\alpha}{2}}(S + 0.5, \ n - S + 0.5) \right],
$$
gdzie
$$
\mathrm{P}(p_0 \in J) \approx 1 - \alpha
$$
pod warunkiem, że hipoteza $H_0$ jest prawdziwa.





\section{Porównanie testów}

|     W powyższych sekcjach przedstawione zostały trzy różne sposoby na testowanie parametru $p$ w rozkładzie dwumianowym. Odpowiemy teraz na pytanie, który z nich oferuje największą moc. W tym celu skorzystamy z metody Monte Carlo. Dla kolejnych wartości $p \in (0, 1)$ wykonujemy następujące kroki:
\begin{enumerate}
  \item generujemy $N = 10\ 000$ realizacji zmiennej losowej $S \sim \mathcal{B}(n, p)$,
  \item dla każdego $S$ z próbki testujemy hipotezę $H_0: p = 0.5$ na poziomie istotności $\alpha = 0.05$, przy pomocy wszystkich trzech testów,
  \item dla każdego z testów zliczamy ile razy hipoteza zerowa została zaakceptowana i dzielimy tę liczbę przez $N$, co daje nam przybliżoną wartość mocy dla danego $p$.
\end{enumerate}
Porównanie mocy wykonamy dla $n \in \{7, 35, 250\}$.

```{r n7, fig.cap="\\label{fig:n7} Wykres zależności mocy testów od parametru $p$ dla $n = 7$", fig.width = 5, fig.height = 3, fig.align="center"}
n <- 7
plots(n)
```

```{r n35, fig.cap="\\label{fig:n35} Wykres zależności mocy testów od parametru $p$ dla $n = 35$", fig.width = 5, fig.height = 3, fig.align="center"}
n <- 35
plots(n)
```

```{r n250, fig.cap="\\label{fig:n250} Wykres zależności mocy testów od parametru $p$ dla $n = 250$", fig.width = 5, fig.height = 3, fig.align="center"}
n <- 250
plots(n)
```

|       Na wykresach 1, 2 i 3 dostrzec można, że krzywe mocy trzech testów dla każdego $n$ wyraźnie się pokrywają. Jak się okazuje, wyliczone wartości mocy są identyczne dla wszystkich trzech testów. Wynik ten, na pierwszy rzut oka, może budzić pewne wątpliwości, jednakże jest on w pełni poprawny. Podstawową przyczyną takich samych wartości mocy jest to, że przeprowadzane testy dotyczą rozkładu dwumianowego, który jest rozkładem dyskretnym. Oznacza to, że zmienna $S \sim \mathcal{B}(n, p)$ przyjmuje ograniczoną liczbę wartości. Przykładowo dla $n = 7$, zmienna $S$ przyjmuje jedynie wartości $0, 1, 2, \dots, 7$. Zatem w tym przypadku mamy 8 możliwych przedziałów.

```{r conf7, fig.cap="\\label{fig:conf7} Przedziały ufności parametru $p_0$ dla $n = 7$", fig.width = 5, fig.height = 3, fig.align="center"}
intervals(7)
```

Okazuje się, że gdy $S$ przyjmuje wartości od 1 do 6, wszystkie z trzech testowych przedziałów zawierają wartość 0.5, co prowadzić będzie do akceptacji $H_0$. Z kolei dla $S = 0$ i $S = 7$ wartość 0.5 nie wpada do żadnego z przedziałów (wykres 4). Stąd każdy z testów zachowuje się dokładnie tak samo.

Czy oznacza to, że nie istnieje test najmocniejszy? Jest to prawda dla rozważanych przez nas prób o długościach $n \in \{7, 35, 250\}$, jednak dla innych rozmiarów może być inaczej (co pokażemy w dalszej części). Zwróćmy uwagę na fakt, że to są testy oparte o przedziały ufności. Jeśli $H_0$ jest prawdziwa, to interesuje nas, z jaką częstotliwością wartość $p_0$ będzie zawarta w przedziale ufności w trakcie próby Bernoulliego. Innymi słowy, nie interesuje nas jak wąski jest przedział ufności, tylko jak często wpada do niego wartość $p_0$. Spójrzmy na wykresy przedziałów dla rozważanych długości prób ($n \in \{7, 35, 250\}$)

```{r conf35, fig.cap="\\label{fig:conf35} Przedziały ufności parametru $p_0$ dla $n = 35$", fig.width = 5, fig.height = 3, fig.align="center"}
intervals(35)
```

```{r conf250, fig.cap="\\label{fig:conf250} Przedziały ufności parametru $p_0$ dla $n = 250$", fig.width = 5, fig.height = 3, fig.align="center"}
intervals(250, 108:142)
```

Na powyższych wykresach wyraźnie widać, że przedział Cloppera-Pearsona jest szerszy od dwóch pozostałych. Dla zbadanych przez nas długości prób, częstotliwość wpadania $p_0$ w przedziały jest identyczna (stąd moce tych testów mają identyczne wartości dla różnych wartości $p$). Co się jednak stanie dla $n = 5$?

```{r conf5, fig.cap="\\label{fig:conf5} Przedziały ufności parametru $p_0$ dla $n = 5$. Wyraźnie widać, że wartość $p_0$ wpada najczęściej w przedział Cloppera-Pearsona", fig.width = 5, fig.height = 3, fig.align="center"}
intervals(5)
```

Możemy zauważyć, że parametr $p_0$ za każdym razem jest zawarty w przedziale Cloppera-Pearsona, podczas gdy dla pozostałych testów nie dzieje się tak dla granicznych wartości $n$. W tym przypadku to właśnie test Cloppera-Pearsona jest najmocniejszy spośród wszystkich, czego nie można było powiedzieć wcześniej.





\section{Podsumowanie}
