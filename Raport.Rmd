---
title: "Porównanie testów dla parametru proporcji w rozkładzie dwumianowym"
author: "Szymon Malec, Michał Wiktorowski"
output:
  pdf_document: 
    number_sections: true
    extra_dependencies: ["polski", "mathtools", "amsthm", "amssymb", "icomma", "upgreek", "xfrac", "scrextend", "float", "tabularx", "hyperref", "caption", "enumitem", "titlesec"]
fontsize: 12pt
---

\renewcommand{\figurename}{Wykres}
\renewcommand{\tablename}{Tablica}
\raggedbottom
\titlelabel{\thetitle.\quad}

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE, eval = TRUE, fig.pos = "H", dev.args=list(encoding="CP1257.enc"))
```

```{r}
library(dplyr)
library(ggplot2)
library(tidyr)
library(knitr)
library(DescTools)


plots <- function(n, p0 = 0.5,
                  alpha = 0.05,
                  z = qnorm(1 - alpha/2),
                  N = 10000,
                  ps = seq(0.01, 0.99, 0.01)){

    power1 <- c()
    power2 <- c()
    power3 <- c()

    for (p in ps) {
        S <- rbinom(N, prob=p, size=n)

        tests <- (S + 1/2 * z^2) / (n + z^2)  -  z / (n + z^2) * sqrt(S * (n - S) / n + z^2 / 4) < p0 & p0 < (S + 1/2 * z^2) / (n + z^2)  +  z / (n + z^2) * sqrt(S * (n - S) / n + z^2 / 4)
        power1 <- append(power1, 1 - sum(tests) / N)

        tests <- qbeta(alpha/2, S, n - S + 1) < p0  &  p0 < qbeta(1 - alpha/2, S + 1, n - S)
        power2 <- append(power2, 1 - sum(tests) / N)

        tests <- qbeta(alpha/2, S + 0.5, n - S + 0.5) < p0  &  p0 < qbeta(1 - alpha/2, S + 0.5, n - S + 0.5)
        power3 <- append(power3, 1 - sum(tests) / N)
    }

    ggplot() + 
      geom_line(aes(ps, power1, col="Wilson"), linewidth=0.5, alpha = 0.7) + 
      geom_line(aes(ps, power2, col="Clopper-Pearson"), linetype="dashed", linewidth=0.9) +
      geom_line(aes(ps, power3, col="Jeffreys"), linetype="dotted", linewidth=1) +
      labs(x = 'p', y = 'Moc testu') + 
      scale_color_manual('', 
          breaks = c('Wilson',
                    'Clopper-Pearson',
                    'Jeffreys'
                    ),
          values = c('#ec1621', '#ffbf00', '#0151ff'))
}


intervals <- function(n, S = 0:n, alpha = 0.05){
    intervals1 <- BinomCI(S, n, method="wilson")
    intervals2 <- BinomCI(S, n, method="clopper-pearson")
    intervals3 <- BinomCI(S, n, method="jeffreys")

    ggplot() +
      geom_point(aes(S, intervals1[,2], col="Wilson"), size = 0.4) + geom_point(aes(S, intervals1[,3], col="Wilson"), size = 0.4) +
      geom_point(aes(S, intervals2[,2], col="Clopper-Pearson"), size = 0.4) + geom_point(aes(S, intervals2[,3], col="Clopper-Pearson"), size = 0.4) +
      geom_point(aes(S, intervals3[,2], col="Jeffreys"), size = 0.4) + geom_point(aes(S, intervals3[,3], col="Jeffreys"), size = 0.4) +
      geom_line(aes(S, 0.5), col="#008f02", linewidth=0.3) +
      labs(x = 'S', y = 'Przedział testowy') + 
      scale_color_manual('', 
          breaks = c('Wilson',
                    'Clopper-Pearson',
                    'Jeffreys'
                    ),
          values = c('#ec1621', '#ffbf00', '#0151ff'))
}
```




\section{Wstęp}

|       Niniejsza praca poświęcona jest przedstawieniu trzech testów dla parametru proporcji (prawdopodobieństwa sukcesu w próbie Bernoulliego) rozkładu dwumianowego. Dla pewnej realizacji zmiennej losowej $S \sim \mathcal{B}(n, p)$ rozważmy hipotezy:
\begin{itemize}
\item $H_0$: $p = p_0 = 0.5$
\item $H_1$: $p \neq p_0 = 0.5$,
\end{itemize}
gdzie $H_0$ i $H_1$ są odpowiednio hipotezą zerową i alternatywną. Sprawdzimy ich poprawność przy użyciu trzech testów:
\begin{itemize}
\item testu opartego o $\textbf{przedział Wilsona}$,
\item testu opartego o $\textbf{przedział Cloppera-Pearsona}$,
\item testu opartego o $\textbf{przedział Jeffreysa}$,
\end{itemize}
na poziomie istotności $\alpha = 0.05$. Następnie porównamy wspomniane testy pod kątem mocy, aby odpowiedzieć na pytanie, czy można wyłonić wśród nich test jednostajnie najmocniejszy.





\section{Test oparty o przedział Wilsona}

|       Do konstrukcji przedziału wykorzystamy fakt, że rozkład dwumianowy można przybliżać rozkładem normalnym. Przyjmuje się, że przybliżenie to jest dobre, gdy $np > 5$, $n(1 - p) > 5$ oraz wartość $p$ jest bliskia 0.5. Wartość oczekiwana $S$ to $\mathrm{E}S = np$, a odchylenie standardowe równe jest $\mathrm{Std}(S) = \sqrt{np(1-p)}$, zatem dla pewnej zmiennej losowej $Z \sim \mathcal{N}(0, 1)$ możemy powiedzieć, że
$$
\frac{S - np_0}{\sqrt{np_0(1 - p_0)}} \stackrel{\mathrm{d}}{\approx} Z
$$
pod warunkiem, że $H_0$ jest prawdziwa. Korzystając z tego, zapisujemy
$$
\mathrm{P}\left( -z < \frac{S - np_0}{\sqrt{np_0(1 - p_0)}} < z \right) \approx 1 - \alpha,
$$
gdzie $z$ jest kwantylem rzędu $1 - \frac{\alpha}{2}$ rozkładu $\mathcal{N}(0, 1)$. Podnosząc strony nierówności wewnątrz funkcji prawdopodobieństwa do kwadratu dostajemy
$$
\mathrm{P}\left( \frac{(S - np_0)^2}{np_0(1 - p_0)} < z^2 \right) \approx 1 - \alpha,
$$
a następnie rozwiązując ukrytą wewnątrz nierówność kwadratową względem $p_0$ otrzymamy
$$
\mathrm{P}(p_0 \in W) \approx 1 - \alpha,
$$
gdzie
$$
W = \left[ \frac{S + \frac{1}{2}z^2}{n + z^2} - \frac{z}{n + z^2} \sqrt{\frac{S(n - S)}{n} + \frac{z^2}{4}} \ , \ \ \frac{S + \frac{1}{2}z^2}{n + z^2} + \frac{z}{n + z^2} \sqrt{\frac{S(n - S)}{n} + \frac{z^2}{4}} \right]
$$
nazywamy przedziałem Wilsona. Widzimy zatem, że przedział ten będzie zmieniać się w zależności od wartości $S$ i jeśli hipoteza zerowa jest prawdziwa, $p_0$ będzie wpadać do niego z częstością zbliżoną do $1 - \alpha$.






\section{Test oparty o przedział Cloppera-Pearsona}

|       Oznaczmy kwantyl rzędu $\gamma$ rozkładu $\mathcal{B}eta(\alpha, \beta)$ jako $b_{\gamma}(\alpha, \beta)$. Dla pewnej realizacji zmiennej $S$, przedział Cloppera-Pearsona przedstawia się w postaci
$$
CP = \left[ b_{\frac{\alpha}{2}}(S, \ n - S + 1), \ \ b_{1 - \frac{\alpha}{2}}(S + 1, \ n - S) \right],
$$
gdzie
$$
\mathrm{P}(p_0 \in CP) \approx 1 - \alpha
$$
pod warunkiem prawdziwości hipotezy zerowej.





\section{Test oparty o przedział Jeffreysa}

|       Przedział ten definiuje się podobnie jak przedział Cloppera-Pearsona, z tą różnicą, że tutaj korzystamy wyłącznie z kwantyli rozkładu $\mathcal{B}(S + 0.5, \ n - S + 0.5)$. Dla pewnej realizacji zmiennej $S$ ma on zatem następującą postać:
$$
J = \left[ b_{\frac{\alpha}{2}}(S + 0.5, \ n - S + 0.5), \ \ b_{1 - \frac{\alpha}{2}}(S + 0.5, \ n - S + 0.5) \right],
$$
gdzie
$$
\mathrm{P}(p_0 \in J) \approx 1 - \alpha
$$
pod warunkiem, że hipoteza $H_0$ jest prawdziwa.





\section{Porównanie testów}

|       W powyższych sekcjach przedstawione zostały trzy różne sposoby na testowanie parametru $p$ w rozkładzie dwumianowym. Odpowiemy teraz na pytanie, który z nich oferuje największą moc. W tym celu skorzystamy z metody Monte Carlo. Dla kolejnych wartości $p \in (0, 1)$ wykonujemy następujące kroki:
\begin{enumerate}
  \item generujemy $N = 10\ 000$ realizacji zmiennej losowej $S \sim \mathcal{B}(n, p)$,
  \item dla każdego $S$ z próbki testujemy hipotezę $H_0: p = p_0 = 0.5$ na poziomie istotności $\alpha = 0.05$, przy pomocy wszystkich trzech testów,
  \item dla każdego z testów zliczamy ile razy hipoteza zerowa została zaakceptowana i dzielimy tę liczbę przez $N$, co daje nam przybliżoną wartość mocy dla danego $p$.
\end{enumerate}
Porównanie mocy wykonamy dla $n \in \{7, 35, 250\}$.

```{r moc7, fig.cap="\\label{fig:moc7} Wykres zależności mocy testów od parametru $p$ dla $n = 7$.", fig.width = 7, fig.height = 4, fig.align="center"}
plots(7)
```

```{r moc35, fig.cap="\\label{fig:moc35} Wykres zależności mocy testów od parametru $p$ dla $n = 35$.", fig.width = 7, fig.height = 4, fig.align="center"}
plots(35)
```

```{r moc250, fig.cap="\\label{fig:moc250} Wykres zależności mocy testów od parametru $p$ dla $n = 250$.", fig.width = 7, fig.height = 4, fig.align="center"}
plots(250)
```

\newpage

|       Na wykresach \ref{fig:moc7}, \ref{fig:moc35} i \ref{fig:moc250} dostrzec można, że krzywe mocy testów dla każdego $n$ wyraźnie się pokrywają. Jak się okazuje, wyliczone wartości mocy są identyczne dla wszystkich trzech testów. Wynik ten, na pierwszy rzut oka, może budzić pewne wątpliwości, jednakże jest on w pełni poprawny. Główną przyczyną takich samych wartości mocy jest to, że przeprowadzane testy dotyczą rozkładu dwumianowego, który jest rozkładem dyskretnym. Oznacza to, że zmienna $S \sim \mathcal{B}(n, p)$ przyjmuje ograniczoną liczbę wartości. Przykładowo dla $n = 7$, zmienna $S$ przyjmuje jedynie wartości $0, 1, 2, \dots, 7$. Zatem w tym przypadku mamy 8 możliwych przedziałów.

```{r conf7, fig.cap="\\label{fig:conf7} Przedziały testowe w zależności od wartości $S$ dla $n = 7$ z wartością $p_0 = 0.5$ oznaczoną zieloną linią.", fig.width = 7, fig.height = 4, fig.align="center"}
intervals(7)
```

Okazuje się, że gdy $S$ przyjmuje wartości od 1 do 6, wszystkie z trzech testowych przedziałów zawierają wartość $p_0 = 0.5$, co prowadzić będzie do akceptacji $H_0$. Z kolei dla $S = 0$ i $S = 7$ wartość 0.5 nie wpada do żadnego z przedziałów (wykres \ref{fig:conf7}). Stąd każdy z testów zachowuje się dokładnie tak samo.

```{r conf35, fig.cap="\\label{fig:conf35} Przedziały testowe w zależności od wartości $S$ dla $n = 35$ z wartością $p_0 = 0.5$ oznaczoną zieloną linią.", fig.width = 7, fig.height = 4, fig.align="center"}
intervals(35)
```

```{r conf250, fig.cap="\\label{fig:conf250} Przedziały testowe w zależności od wartości $S$ dla $n = 250$ z wartością $p_0 = 0.5$ oznaczoną zieloną linią.", fig.width = 7, fig.height = 4, fig.align="center"}
intervals(250, 108:142)
```

|       Na wykresach \ref{fig:conf35} i \ref{fig:conf250} zobaczyć można jak wyglądają przedziały trzech testów w zależności od wartości $S$ w kolejnych dwóch przypadkach, czyli $n = 35$ oraz $n = 250$. Jak się okazuje, mamy do czynienia z tą samą sytuacją. Nie występuje ani jedna wartość $S$, dla której któryś z przedziałów zawierałby 0.5, a któryś nie (taka sytuacja spowodowałaby różnicę w mocy). Zatem dla rozpatrywanych przez nas wartości $n$ oraz $\alpha = 0.05$ nie da się wyłonić testu jednostajnie najmocniejszego, ponieważ wszystkie testy są równe. Nie oznacza to jednak, że jest tak dla każdego $n$ i dowolnego poziomu istotności $\alpha$. Zwiększenie wartości $\alpha$ spowodowałoby zwiększenie długości przedziałów, co mogłoby skutkować tym, że któryś z przedziałów "zjadłby" 0.5. Na podstawie wykresów możemy wywnioskować, że tym przedziałem byłby ten pochodzący z testu Cloppera-Pearsona, ponieważ jest on największy.

|       Rozpatrzmy jeszcze przypadek $n = 5$. Na wykresie \ref{fig:conf5} dostrzec można coś ciekawego. Mianowicie przedział Cloppera-Pearsona dla każdego $S$ zawiera $p_0$, czego nie można powiedzieć o dwóch pozostałych przedziałach. Takie zachowanie będzie prowadziło do sytuacji, w której niezależnie jaką wartość przyjmie $S$, test Cloppera-Pearsona będzie akceptował fałszywą hipotezę zerową (czyli będzie popełniał błąd II rodzaju), skutkiem czego test ten będzie miał moc równą zero dla każdego $p \in (0, 1)$, co zobaczyć możemy na wykresie \ref{fig:moc5}.

```{r conf5, fig.cap="\\label{fig:conf5} Przedziały testowe w zależności od wartości $S$ dla $n = 5$ z wartością $p_0 = 0.5$ oznaczoną zieloną linią.", fig.width = 7, fig.height = 4, fig.align="center"}
intervals(5)
```

```{r moc5, fig.cap="\\label{fig:moc5} Wykres zależności mocy testów od parametru $p$ dla $n = 5$.", fig.width = 7, fig.height = 4, fig.align="center"}
plots(5)
```





\section{Podsumowanie}

|      Rozważaliśmy trzy testy dla parametru $p$ rozkładu dwumianowego $\mathcal{B}(n, p)$ oparte o następujące przedziały:
\begin{itemize}
\item przedział Wilsona,
\item przedział Cloppera-Pearsona,
\item przedział Jeffreysa.
\end{itemize}
Aby stwierdzić, który z tych testów jest jednostajnie najmocniejszy, przeprowadziliśmy symulację mocy dla $n \in \{7,35,250\}$. Jak się okazało, wszystkie testy były tak samo mocne. Nie oznacza to jednak, że dla innych wartości $n$ jest tak samo - dla $n=5$ przeprowadziliśmy analogiczną symulację. Okazało się, że w tym przypadku można wyłonić test najsłabszy - test Cloppera-Pearsona. 
